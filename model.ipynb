{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Behavioral Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading package is a sucess!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "%matplotlib inline\n",
    "from multiprocessing import Queue\n",
    "# Load pickled data\n",
    "import pickle\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "print(\"Loading package is a sucess!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples  = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(csvfile)\n",
    "    for line in reader:\n",
    "        #print(line)\n",
    "        samples.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)        \n",
    "\n",
    "\n",
    "print(len(train_samples))\n",
    "samples_per_epoch = len(train_samples)/32\n",
    "val_size = int(samples_per_epoch/10.0)\n",
    "\n",
    "# samples contains all the lines in the csv file\n",
    "def trainningdata_gen(samples, batch_size = 32):\n",
    "    num_samples = len(samples)\n",
    "\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "        for offset in range(0,num_samples,batch_size):\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "            images = []\n",
    "            measurements = []\n",
    "            for line in batch_samples:\n",
    "                # firstly store the center image\n",
    "                source_path_center = line[0]\n",
    "                filename_center = source_path_center.split('/')[-1]\n",
    "                current_path_center = ('data/IMG/')+filename_center\n",
    "                image_center = cv2.imread(current_path_center)\n",
    "                images.append(image_center)\n",
    "                measurement = float(line[3])\n",
    "                measurements.append(measurement)\n",
    "                images.append(cv2.flip(image_center,1))\n",
    "                measurements.append(measurement*-1.0)\n",
    "                \n",
    "            \n",
    "                # Then store the left image\n",
    "                source_path_left = line[1]\n",
    "                filename_left = source_path_left.split('/')[-1]\n",
    "                current_path_left = ('data/IMG/')+filename_left\n",
    "                image_left = cv2.imread(current_path_left)\n",
    "                images.append(image_left)\n",
    "                measurements.append(measurement+0.2)\n",
    "                images.append(cv2.flip(image_left,1))\n",
    "                measurements.append((measurement+0.2)*-1.0)\n",
    "                \"\"\"\n",
    "                # Then store the right image\n",
    "                source_path_right = line[2]\n",
    "                filename_right = source_path_right.split('/')[-1]\n",
    "                current_path_right = ('data/IMG/')+filename_right\n",
    "                image_right = cv2.imread(current_path_right)\n",
    "                images.append(image_right)\n",
    "                measurements.append(measurement-0.4)\n",
    "                images.append(cv2.flip(image_right,1))\n",
    "                measurements.append((measurement-0.4)*-1.0)\n",
    "               \"\"\"\n",
    "            \n",
    "                \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "            yield X_train,y_train\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show the first three image to visualize the trainning set\n",
    "train_generator = trainningdata_gen(train_samples, batch_size=32)\n",
    "\n",
    "validation_generator = trainningdata_gen(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading keras is a sucess!\n"
     ]
    }
   ],
   "source": [
    "# Import the Keras package\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dropout,Dense,ELU, Lambda, Activation\n",
    "from keras.layers import SpatialDropout2D,Cropping2D,Convolution2D,MaxPooling2D\n",
    "from sklearn.utils import shuffle\n",
    "print(\"Loading keras is a sucess!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 160, 320, 3)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)        (None, 65, 320, 3)    0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 158, 24)   1824        cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 77, 36)    21636       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 37, 48)     43248       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 35, 64)     27712       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 33, 128)    73856       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 4224)          0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 400)           1690000     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 200)           80200       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 100)           20100       dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 75)            7575        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 50)            3800        dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 25)            1275        dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 20)            520         dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             21          dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,971,767\n",
      "Trainable params: 1,971,767\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/4\n",
      "25712/25712 [==============================] - 53s - loss: 0.0337 - acc: 0.2695 - val_loss: 0.0164 - val_acc: 0.2730\n",
      "Epoch 2/4\n",
      "25712/25712 [==============================] - 50s - loss: 0.0159 - acc: 0.2709 - val_loss: 0.0143 - val_acc: 0.2730\n",
      "Epoch 3/4\n",
      "25600/25712 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.2710"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# normolize the image around the center\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "        input_shape=(160, 320, 3),\n",
    "        output_shape=(160, 320, 3)))\n",
    "# crop the image\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0)),\n",
    "                     dim_ordering='tf', # default\n",
    "                     input_shape=(160, 320, 3)))\n",
    "# First layer of CNN\n",
    "model.add(Convolution2D(24,5,5,subsample=(2, 2),activation = \"relu\"))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2, 2),activation = \"relu\"))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2, 2),activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3,activation = \"relu\"))\n",
    "model.add(Convolution2D(128,3,3,activation = \"relu\"))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(400))\n",
    "\n",
    "model.add(Dense(200))\n",
    "\n",
    "model.add(Dense(100))\n",
    "\n",
    "model.add(Dense(75))\n",
    "\n",
    "model.add(Dense(50))\n",
    "\n",
    "model.add(Dense(25))\n",
    "\n",
    "model.add(Dense(20))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath=\"./tmp/comma-4c.{epoch:02d}-{val_loss:.2f}.hdf5\", verbose=1, save_best_only=False)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit_generator(train_generator, samples_per_epoch=\n",
    "            len(train_samples)*4, validation_data=validation_generator,\n",
    "            nb_val_samples=len(validation_samples)*4, nb_epoch=4)\n",
    "model.save('olddatamodel_left.h5')\n",
    "print('Work is finished')\n",
    "exit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
